---
title: 핸즈온 머신러닝2판 1장 한눈에보는 머신러닝 1.5 ~1.6 리뷰
layout: post   
categories : [ai]
image : /assets/img/study/ml/over_under_fitting.jpg
description:  머신러닝에 대한 거식적인 소개를 함
customexcerpt: "모든 데이터 과학자가 꼭 알아야 할 여러가지 기초 개념과 용어를 소개(2)" 
---

작성자 : 김아영

# 1.5 머신러닝의 주요 도전 과제

* random line to make it work. This will be removed.
{:toc}

## 1.5.1 충분하지 않은 양의 훈련 데이터
머신러닝 알고리즘은 데이터가 많아야 잘 작동함. 간단한 문제에서도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 **수백만 개**가 필요할지도 모름(이미 만들어진 모델을 재사용할 수 없다면ㅇㅇ)
## 1.5.2 대표성 없는 훈련 데이터
일반화가 잘 되려면 ? 일반화하기 원하는 새로운 사례를 **훈련 데이터가 잘 대표하는 것**이 중요  

일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만, 어려울때가 많음.샘플이 작으면 **샘플링잡음**(우연에 의해 대표성이 없는 데이터)이 생김.  
샘플링 편향 : 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못하는것  
## 1.5.3 낮은 품질의 데이터
훈련 데이터가 에러, 이상치, 잡음(ex. 낮은 성능을 가진 측정 장치 때문)들이 가득하면 머신러닝이 내재된 패턴을 찾기 어려워 잘 작동하지 않을것이다. 그렇기에 **훈련 데이터 정제**에 많은 시간을 할애하고 있음.  

**데이터 정제가 필요한 경우**
* 이상치 샘플이라면 고치거나 무시함.
* 특성이 누락되었을때  
    - 해당 특성을 제외
    - 해당 샘플을 제외
    - 누락된 값 채움
    - 해당 특성을 넣은 경우와 뺀 경우 각기 모델을 훈련

## 1.5.4 관련없는특성
특성공학 : 훈련에 사용할 좋은 특성들을 찾는 과정
- 특성 선택 : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
- 특성 추출 : 새로운 데이터 수집후, 특성을 결합해 더 유용한 특성을 만듦. (ex.차원축소)

## 1.5.5 훈련 데이터 과대적합

![1](/assets/img/study/ml/over_under_fitting.jpg)


과대적합(overfitting) : 기계가 과도하게 일반화를 하는 함정이 빠지는것(= 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다는것)  
*CAUTION* 과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 떄 일어남.  
해결방법 : 1. 파라미터 수가 적은 모델을 선택하거나(예를 들면 고차원 다항 모델보다 선형 모델), 훈련 데이터에 있는 특정 수를 줄이거나, 모델에 제약을 가하여 단순화시킴  
2. 훈련 데이터를 더 많이 모은다  
3. 훈련 데이터이ㅡ 잡음을 줄임(ex. 오류데이터 수정과 이상치 제거)

규제 : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것  
학습하는 동안 적용할 규제의 양은 하이퍼파라미터(학습 알고리즘의 파라미터)가 결정 -> 학습 알고리즘으로부터 영향을 받지 않고 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있음. 규제하이퍼파라미터를 매우 큰 값(기울기가 0에 가까운)으로 지정하면 거의 평편한 모델을 얻게 됨. 학습 알고리즘이 훈련 데이터에 과대적합될 가능성은 거의 없겠지만 좋은 모델을 찾지 못함. 
## 1.5.6 훈련 데이터 과소적합
과소적합 :  과대적합의 반대  => 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생함.  
해결방법 : 1. 모델 파라미터가 더 많은 강력한 모델을 사용함
2. 특성 공학으로 더 좋은 특성을 찾음
3. 규제의 강도를 줄임

## 1.5.7 한걸음 물러서서 머신러닝의 큰 그림 보기
* 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것
* 여러 종류의 머신러닝 시스템이 있음. 지도 학습과 비지도 학습, 배치 학습과 온라인 학습, 사례기반학습과 모델 기반 학습
* 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입함. 학습알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하고(즉, 훈련 세트에서 좋은 예측을 만들기 위해) 새로운 데이터에서도 좋은 예측을 만들 거라 기대함. 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 유사도 측정을 사용해 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플에 일반화함
* 훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않음. 마지막으로, 모델이 너무 단순하거나(과소적합된 경우) 너무 복잡하지 않아야 함(과대적합된 경우)

# 1.6 테스트와 검증
1. 테스트 세트와 검증 세트
   * 모델의 일반화 성능을 측정하기 위해 훈련 세트와 테스트 세트로 나눔
   * 훈련 세트로 모델을 훈련하고 테스트 세트로 모델의 일반화 성능을 측정
   * 하이퍼파라미터는 알고리즘을 조절하기 위해 사전에 정의하는 파라미터
   * 테스트 세트를 사용해 여러 모델을 평가하면 테스트 세트에 과대적합됨
   * 모델 선택을 위해 훈련 세트, 검증세트(개발세트), 테스트 세트로 나눔

2. 훈련-개발 세트
   * 대량의 데이터를 얻기 위해 실전과 다른 데이터로 훈련 세트를 만들 때
   * 이런 경우 검증 세트 점수가 과대적합과 데이터 불일치 중 어떤 것이 원인인지 모름
   * 이를 위해 훈련-개발 세트를 만들어 훈련한 모델 평가
      * 훈련 개발 세트 성능이 낮다면 과대적합
      * 검증 세트 성능이 낮다면 데이터 불일치 문제