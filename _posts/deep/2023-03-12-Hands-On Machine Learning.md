---
title: 핸즈온 머신러닝2판 1장 한눈에보는 머신러닝 1.1 ~ 1.4 리뷰
layout: post   
categories : [ai]
image : /assets/img/study/ml/1.4.2-비지도학습-시각화.png
description:  머신러닝에 대한 거식적인 소개를 함. 나머지 내용을 시작하기전에 이 내용들을 완벽하게 이해해야함.
customexcerpt: "모든 데이터 과학자가 꼭 알아야 할 여러가지 기초 개념과 용어를 소개합니다!" 
---

작성자 : 김아영

# ch1. 한눈에 보는 머신러닝

* random line to make it work. This will be removed.
{:toc}

## 1.1 머신러닝이란 ?
---
데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학(OR 예술)  
일반적인 정의 : [머신러닝은] 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야 -아서 새뮤얼,1959-  
공학적인 정의 : 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것 -톰 미첼,1997-  
ex) 스팸(사용자가 스팸이라고 지정한) 필터는 스팸 메일과 일반 메일의 샘플을 이용해 스팸 메일 구분법을 배울 수 있는 머신러닝 프로그램    
훈련세트 : 시스템이 학습하는 데 사용하는 샘플    
훈련사례(샘플) : 각 훈련 데이터    
훈련데이터 : 작업 T는 새로운 메일이 스팸인지 구분하는것, 경험 E는 훈련데이터이며, 성능 측정 P는 직접 정의해야함  
정확도 : 성능 측정
## 1.2 왜 머신러닝을 사용하는가 ?  
---
전통적인 프로그래밍 기법 사용해 스팸 필터를 만들면 ?  
1. 스팸에 어떤 단어들이 주로 나타나는지 살펴보기. 그러면 '4U','신용카드','무료','굉장한'같은 단어나 구절이 제목에 많이 나타나는 경향이 있다는것을 알수있음.   어쩌면 보낸이의 이름이나 메일 주소, 본문이나 이메일의 다른 요소에서 다른 패턴을 감지할 수도 있음.  
2. 발견한 각 패턴을 감지하는 알고리즘을 작성해 프로그램이 이런 패턴을 발견했을 떄 그 메일을 스팸으로 분류하게 함.  
3. 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때까지 1단계와 2단계를 반복함.      
![그림1-1](/assets/img/study/ml/1.jpg)  
문제가 어렵기 때문에 **규칙이 점점 길어지고 복잡해지므로 유지 보수하기 매우 힘들어짐**      
머신러닝에 기반을 둔 스팸 필터는 일반 메일에 비해 스팸에 자주 나타나는 **패턴을 감지**해 **어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준**인지 자동으로 학습함.그러므로 프로그램이 **훨씬 짧아지고 유지 보수하기 쉬우며 정확도 높음**.  
![그림1-2](/assets/img/study/ml/1-1.jpg)
만약 스팸메일 발송자가 '4U'를 포함한 모든 메일이 차단된다는것을 인지하고 'For U'를 쓰기 시작한다면 전통적인 프로그래밍 방식으로는 'For U 메일을 구분하기 위해 수정이 필요. 스팸 메일 발송자가 스팸 필터에 대항해 계속 단어를 바꾸면 **영원히 새로운 규칙을 추가해야함**    
*but* 머신러닝 기반의 스팸 필터는 사용자가 스팸으로 지정한 메일에 유동 'For U'가 자주 나타나는 것을 자동으로 인식하고 별도의 작업을 하지 않아도 자동으로 이 단어를 스팸으로 분류
![그림1-3](/assets/img/study/ml/1-2.jpg)
머신러닝이 유용한 또 다른 분야 : 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제  
ex) 음성 인식 : 'one'과'two' 두 단어를 구분하는 프로그램 작성한다고 하자. 단어 'two'는 높은 피치의 사운드 'T'로 시작하므로 높은 피치의 사운드 강도를 측정하는 알고리즘을 하드코딩해 구분할수 있음. 이 구분법은 소음이 있는 환경에서 수백만 명이 말하는 여러 언어로 된 수천개의 단어를 구분하는 것으로 확장하기 어려움. 각 단어를 녹음한 샘플을 사용해 스스로 학습하는 알고리즘을 작성하는 것이 현재 가장 좋은 솔루션임.  
머신러닝을 통해 배울 수 있음=머신러닝 알고리즘이 학습한 것을 조사할 수 있음. ex) 스팸 필터가 충분한 스팸 메일로 훈련되었다면, 스팸을 예측하는 데 가장 좋은 단어 및 단어의 조합이 무엇인지 확인할 수 있음. 가끔 예측하지 못한 연관 관계나 새로운 추세가 발견되어도 해당 문제를 더 잘 이해하도록 도와줌. **머신러닝 기술을 적용해 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴 발견 가능**-> ***데이터 마이닝***    
![그림1-4](/assets/img/study/ml/1-3.jpg)
* 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제: 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있음.
* 전통적인 방식으로는 해결 방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있음.
* 유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있음.
* 복잡한 문제와 대량의 데이터에서 통찰 얻기

## 1.3 애플리케이션 사례
---
* 제품 이미지를 보고 자동으로 분류 ->CNN(14장)
* 뇌를 스캔해 종양 진단하기 ->
* 자동으로 뉴스 기사를 분류하기 -> 자연어처리(NLP) = RNN(순환신경)+CNN or 트랜스포머
* 내년도 회사의 수익을 예측하기 -> 숫자값 예측(회귀) : 선형회귀, SVM(support vector machine), 랜덤 포레스트
* 음성을 듣고 이해하는 앱 만들기 -> 순차적으로 처리하는 sequence data : RNN, CNN, 트랜스포머 /자동으로 뉴스 기사 분류하기와 같음
* 구매 이력을 기반으로 고객을 나누기 -> 군집(clustering)

## 1.4 머신러닝 시스템의 종류
---
* 사람이 **감독하에 훈련**하는 것인지 그렇지 않은 것인지 (지도, 비지도, 준지도, 강화학습)
* 실시간으로 **점진적인 학습**을 하는지 아닌지(온라인 학습과 배치 학습)
* 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 **예측 모델을 만드는지**(사례 기반 학습과 모델 기반 학습)
### 1.4.1 지도 학습과 비지도 학습
----
학습하는 동안의 감독 형태나 정보량에 따라 분류 -> 지도학습, 비지도학습, 준지도학습, 강화학습

**지도학습-알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함(정답이 존재해 그 정답을 맞추는)**  
분류(clustering)가 전형적인 지도 학습 작업. 스팸 인지아닌지 판별하는것이 좋은 예시
* 회귀 : 예측변수라 부르는 특성을 사용해 타깃수치를 예측하는 작업  
시스템을 훈련시키기 위해서는 **예측변수**와 **레이블**이 포함된 많은 데이터가 필요
* 로지스틱 회귀 : 클래스에 속할 확률을 출력

대표적인 **지도학습 알고리즘**
1. k-최근접 이웃
2. 선형회귀
3. 로지스틱 회귀
4. 서포트 벡터 머신(SVM)
5. 결정 트리와 랜덤 포레스트
6. 신경망

**비지도 학습 : 훈련 데이터에 레이블이 없음(정답이 없음)->시스템이 아무런 도움 없이 학습해야함**  
1. **군집**
   * k-평균
   * DBSCAN
   * 계층 군집 분석(HCA)  
    ![그림1-7](/assets/img/study/ml/1.4.1-비지도학습-군집.png)
2. 이상치탐지와 특이치 탐지
   * 원-클래스
   * 아이솔레이션 포레스트
3. **시각화**와 차원 축소
   * 주성분 분석(PCA)
   * 커널 PCA
   * 지역적 선형 임베딩(LLE)
   * t-SNE  
  ![그림1-8](/assets/img/study/ml/1.4.2-비지도학습-시각화.png)
1. 연관 규칙 학습
   * 어프라이어리
   * 이클렛

시각화 : 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어줌. 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로(예를들어 입력 공간에서 떨어져 있던 클러스터는 시각화된 그래프에서 겹쳐지지 않게 유지됨)데이터가 어떻게 조직되어 있는지 이해할 수 있고 에상하지 못한 패턴을 발견할 수도 있음.  

차원 축소 : 너무 많은 정보를 잃지 않으면서 데이터를 간소화하는것. 이렇게 하는 한가지 방법은 상관관계가 있는 여러 특성을 하나로 합치는 것.  

특성 추출 : 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있음.  

이상치 탐지 : 시스템은 훈련하는 동안 대부분 정상 샘플을 만나 이를 인식하도록 훈련함. 그다음 새로운 샘플을 보고 정상 데이터인지 혹은 이상치인지 판단함.  

특이치탐지 : 훈련세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적. 알고리즘으로 감지하고 싶은 모든 샘플을 제거한 매우 '깨끗한' 훈련 세트가 필요함  
ex) 강아지 사진이 수천장이 존재하고 그중 1%의 치와와 사진이 있다면 특이치-탐지 알고리즘의 경우, 치와와 사진을 새로운 특이한 것으로 처리하지 못함. 반면에, 이상치 탐지 알고리즘은 이 강아지 사진은 매우 드물고 다른 강아지와 다르다고 인식해 이상치로 분류할 것임  

연관 규칙 학습 : 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는것  
  
**준지도학습  : 일부만 레이블이 있는 데이터 다루기 가능(정답이 일부만 존재). 준지도학습 = 지도학습 + 비지도 학습 ex) 구글 포토 호스팅 서비스**  
심층 신뢰 신경망(DBM): 여러 겹으로 쌓은 제한된 볼츠만 머신(RBM)이라 불리는 비지도 학습에 기초. RBM이 비지도 학습 방식으로 순차적으로 훈련된 다음 전체 시스템이 지도 학습 방식으로 세밀하게 조정됨.  

![그림1-11](/assets/img/study/ml/1-4-1-준지도학습.png)  
두 개의 클래스(삼각형과 사각형)를 사용한 준지도 학습 : 새로운 샘플(곱셈기호)이 레이블이 있는 사각형 클래스에 더 가깝지만 레이블이 없는 샘플(원)이 이 샘플을 삼각형 클래스로 분류하는 데 도움을 줌  

**강화학습 : 매우 다른 종류의 알고리즘. 학습하는 시스템을 에이전트라고 호칭. 환경을 관찰해서 행동을 실행하고 그 결과로 *보상*(또는 부정적인 보상에 해당하는 벌점)을 받음. 시간이 지나면서 가장 큰 보상을 얻기위해 *정책*이라고 부르는 최상의 전략을 스스로 학습함. 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의**
![그림1-12](/assets/img/study/ml/1-4-1%20강화학습.png)

### 1.4.2 배치 학습과 온라인 학습 
----
입력 데이터의 스트림으로부터 점진적으로 학습할수 있는지 여부(훈련하는 방식에 따라 분류)  

**배치 학습 : 시스템이 점진적으로 학습할 수 없음. 가용한 데이터를 모두 사용해 훈련시켜야함.**
위와 같은 방식은 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행됨. 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습없이 실행됨. 즉, 학습한 것을 단지 적용만 함. -> **오프라인 학습**  
배치 학습 시스템이 새로운 데이터에 대해 학습 할려면 전체 데이터를 사용해 시스템의 새로운 버전을 청므부터 다시 훈련해야함. 그런 다음 이전 시스템을 중지시키고 새 시스템으로 교체함. but, 그림 1-3과 같이 머신러닝 시스템을 훈련, 평가, 론칭하는 전체 과정이 쉽게 자동화 될 수 있어서 배치 학습 시스템도 변화에 적응할 수 있음. 데이터를 업데이트하고 시스템의 새 버전을 필요한 만큼 자주 훈련시키면 됨. 이러한 방식이 간단하고 잘 작동하지만 전체 데이터셋을 사용해 훈련하는 데 몇 시간이 소요될 수 있음. 보통 24시간마다 또는 매주 시스템을 훈련시킴. 시스템이 빠르게 변하는 데이터(ex. 주식)에 적응해야 한다면 더 능동적인 방법이 필요. 또한 전체 데이터셋을 사용해 훈련한다면 많은 컴퓨팅 자원이 필요. 대량의 데이터를 가지고 있는데 매일 처음부터 새로 훈련시키도록 시스템을 자동화한다면 큰 비요이 발생할 것. 데이터 양이 아주 많으면 배치 학습 알고리즘을 사용하는게 불가능 할 있음. finally, 자원이 제한된 시스템이 스스로 학습해야 할 때 많은 양의 훈련 데이터를 나르고 학습을 위해 매일 몇 시간씩 많은 자원을 사용하면 심각한 문제를 일으킴. 이런 경웨는 점진적으로 학습할 수 있는 알고리즘을 사용하는 편이 나음  

**온라인 학습 : 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴. 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있음.**  

온라인 학습은 **연속적으로 데이터를 받고 빠른 변화에 스스로 적응**해야하는 시스템에 적합. **컴퓨팅 자원이 제한**된 경우에도 적합. 온라인 학습 시스템이 새로운 데이터 햄플을 학습하면 학습이 끝난 데이터는 더는 필요하지 않으므로 버리면 됨. 그러면 많은 공간을 절약하기 가능.  
외부메모리 학습 : 컴퓨터 한대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 온라인 학습 알고리즘을 사용할 수 있음. 알고리즘이 데이터 일부를 읽어 들이고 훈련 단계를 수행. 전체 데이터가 모두 적용될 때까지 이과정 반복.  

학습률 : 변화하는 데이터에 얼마나 빠르게 적응할 것인지 -> 학습률이 높으면 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림. 반대로 학습률이 낮으면 시스템의 관성이 더 커져 더 느리게 학습됨. 하지만 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐.  

문제점 : 시스템에 나쁜 데이터가 주어졌을때, 시스템 성능이 점진적으로 감소함.


***


**온라인 학습**
* 적은 데이터를 사용해 점진적으로 훈련
* 실시간 시스템이나 메모리가 유사도를 측정

**배치 학습**
* 전체 데이터를 사용해 오프라인에서 훈련
* 컴퓨팅 자원이 풍부한 경우에 사용

***



### 1.4.3 사례 기반 학습과 모델 기반 학습
머신러닝은 주어진 훈련 데이터로 학습하고 훈련 데이터에서는 본 적 없는 새로운 데이터에서 좋은 예측을 만들어야함. 훈련 데이터에서 높은 성능을 내는 것이 좋지만 그게 전부가 아니고 **새로운 샘플에 잘 작동하는 모델**  
**사례 기반 학습**  
* 시스템이 훈련 샘플을 기억함으로써 학습
* 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하면서 일반화함  
![그림1-15](/assets/img/study/ml/1-4-3%20사례기반학습.png)
**모델 기반 학습** 
* 샘플들의 모델을 만들어 예측에 사용하는것  
![그림1-16](/assets/img/study/ml/1-4-3%20모델기반학습.png)  

