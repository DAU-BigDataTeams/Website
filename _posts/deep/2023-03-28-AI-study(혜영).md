---
title: 케라스 창시자에게 배우는 딥러닝 1장 리뷰!
layout: post   
categories : [ai]
image : /assets/img/study/deep/ch01/ch1-1.png
description: 
customexcerpt: 케라스 창시자에게 배우는 딥러닝 1장을 리뷰하며 스터디를 진행했습니다.
---

<span class = "alert g">작성자 : 김혜영</span>

* random line to make it work. This will be removed.
{:toc}

# 1장 딥러닝이란 무엇인가?
AI의 정의와 개념, 머신 러닝의 간단한 개요, 역사와 최근 AI 동향에 대해서 살펴보았다.

## 1.1 인공 지능과 머신 러닝, 딥러닝

AI의 정확한 정의는 무엇일까? 사람마다 다르게 느껴지는 AI에 대해 알아보자. AI는 **Artificial Intelligence**의 약자로 한국어로 번역하면 인공지능이 된다. 말 그대로 인간이 만들어낸 지능을 의미한다. AI분야는 1950년대에 태동했다. 당시의 과학자들이 한 '컴퓨터가 생각할 수 있는가?'라는 질문에서 AI가 시작됐다. 

![1](/assets/img/study/deep/ch01/ch1-1.png)

위의 사진에서 알 수 있듯이 AI는 머신러닝과 딥러닝을 포괄하는 학문이다.

---
<br>
 AI가 태동되던 시기의 AI는 대부분 심볼릭 AI였다. 심볼릭 AI는 명시적인 규칙을 충분히 많이 만들어 데이터 베이스에 저장된 지식을 다루는 AI이다. 심볼릭 AI는 이미지, 음성 인식 등의 복잡하고 불분명한 문제를 해결하기 위한 명확한 규칙을 찾지 못한다는 단점이 있었다. 이 단점으로 심볼릭 AI는 머신러닝으로 빠르게 대체되었다.
 
>심볼릭 AI분야에서는 기계가 **학습**한다는 개념은 정립되지 않았다.

---

![2](/assets/img/study/deep/ch01/ch1-2.2.PNG)

전통적인 프로그래밍은 **데이터와 규칙**이 입력되고 그에 따른 **해답**을 프로그래밍 결과로 도출해낸다. 하지만, 머신러닝은 **데이터와 해답**이 입력되고 머신러닝 알고리즘을 통해서 데이터와 해답사이의 **규칙**을 찾아내며 그 규칙을 **학습**한다. 
머신러닝은 프로그래밍하는 것이 아닌 **훈련**이라 지칭한다.
>AI의 선구자인 앨런 튜링은 튜링 테스트와 AI의 주요 개념을 소개한 논문 "Computing Machinery and Intelligence"에서 인간 지능의 모든 면을 모방하는 컴퓨터를 만들 수 있다고 생각했다. 

---
머신러닝을 진행하기 위해서는 세 가지 요소가 필요하다
* 입력 데이터 포인트 : 학습에 적학한 데이터의 형태 
* 기대 출력 : 입력되는 데이터의 예상 출력 값
* 알고리즘의 성능을 측정하는 방법 

**알고리즘의 성능을 측정하는 방법**은 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정하기 위해서 필요하다. 머신러닝은 데이터를 입력해서 나온 출력값과 기대 출력 값의 차이를 피드백 하며 **학습**되기 때문이다. 
머신러닝은 주어진 데이터를 활용해 학습을 하게 되는데, 이 때 데이터를 학습하기 용이한 형태로 **표현**하는 것이 중요한 과제이다.



![1](/assets/img/study/deep/ch01/ch1-3.png)  

<br>
간단한 예시로 표현이 무엇인지 살펴보자.

흰 색 포인트와 빨간색의 포인트가 있을 때, 포인트 좌표를 입력받고 그 포인트가 빨간색인지 흰색인지를 출력하는 알고리즘을 개발하고자 한다.

* 입력 데이터 포인트 : 좌표
* 기대 출력 : 입력된 포인트의 색깔
* 알고리즘의 성능 : 정확히 분류한 포인트의 비율을 사용해 측정하는 것


문제를 쉽고 간단하게 풀기 위해선 흰색과 빨간색 포인트를 완벽하게 구분하는 새로운 데이터 표현을 이용하면 된다.   
![1](/assets/img/study/deep/ch01/ch1-4.png)  

<br>
이 사진과 같이 **좌표 변환**을 통해서 데이터를 새로이 표현하면 간단하게 문제를 풀 수 있다 **'x > 0인 것은 빨간색 포인트다.'** 혹은 **'x < 0인 것은 흰색 포인트이다.'** 같이 한 문장으로 문제를 풀이할 수 있다.
이런 간단한 문제에선 인간이 손으로 직접 데이터를 표현할 수 있지만 데이터셋이 많아지거나 복잡해진다면 수동으로 표현하는 것에는 한계가 있다. 학습은 이런 **유용한 데이터 표현을 만드는 데이터 변환을 피드백 신호를 바탕으로 자동으로 탐색하는 과정을 의미한다.**


---

![1](/assets/img/study/deep/ch01/ch1-5.PNG)  

**딥러닝에서 딥(deep)의 의미는 무엇일까?** 딥러닝은 머신 러닝의 한 분야이다. 연속된 **층**을 이용해서 머신 러닝을 진행하는 기술을 의미한다. 이때, 딥(deep)은 위의 사진처럼 **연속된 층으로 표현을 학습한다는 개념을 의미한다.** 딥러닝의 다른 이름으론 층 기반 표현 학습또는 계층적 표현 학습이 있다.
> 머신 러닝의 다른 접근 방법에는 1~2개의 데이터 표현 층을 학습하는 얕은 학습이 있다.


딥러닝은 층을 쌓아 올려 구성한 **신경망(Neural Net)** 이라는 모델을 사용해 층 기반 표현을 학습한다. 

![1](/assets/img/study/deep/ch01/ch1-6.png)
위 그림처럼 딥러닝은 **데이터를 표현을 학습하기 위한 다단계 처리 방식**을 의미한다.

---

![1](/assets/img/study/deep/ch01/ch1-7.png)  

<br>
**딥러닝의 원리에 대해 알아보겠다.** 각 층에는 어떤 일련의 숫자로 이뤄진 가중치가 저장되어 있다. (어떤 층에서 일어나는 변환은 그 층의 가중치를 파라미터로 가지는 함수로 표현된다.) 딥러닝에서의 학습은 **주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 가중치를 찾아가는 것**을 의미한다. 이 가중치를 방법에 대해서 소개하겠다.

<br> 

![1](/assets/img/study/deep/ch01/ch1-8.png)
<br>
데이터 X를 입력한 뒤 임의로 설정된 가중치에 따라 결과값 Y'가 도출되었다 가정해보자. 도출된 Y'값은 데이터 셋에 있는 정답 Y와 차이가 있을 것이다. 이때 진짜 타겟 Y값과 도출한 결과 Y'의 차이를 손실함수를 이용해 어느정도 차이가 났는지 확인할 수 있다.

>때에 따라 손실 함수(Loss Function)은 비용 함수(Cost Function)또는 목적 함수(Target Function)으로 불리기도 한다.


![1](/assets/img/study/deep/ch01/ch1-9.png)  

<br>

이제 이 손실 점수를 이용해 층의 가중치를 수정할 수 있다. 기본적인 딥러닝 방식은 이 **손실 점수를 피드백 신호로 사용해 현재 샘플의 손실 점수가 감소하는 방향으로 가중치를 조금씩 수정하는 것이다.** 이런 수정과정은 딥러닝의 **역전파(Backpropagation)** 알고리즘을 이용한 **옵티마이저**가 담당한다. 이렇게 지속적으로 손실 점수가 줄어드는 방향으로 학습시키는 것이 딥러닝의 **훈련 반복**이라고 한다.

---

머신 러닝은 지금까지 다양한 분야에서 성과를 냈다. 최근에는 가장 비전있는 기술이지만 머신러닝은 과거에 알고리즘과 하드웨어 자원의 문제로 두번의 **AI 겨울**을 겪은 적 있다. 


--- 

## 1.2 딥러닝 이전: 머신 러닝의 간략한 역사 
딥러닝 이전의 머신러닝은 어떤 역사를 가지고 있을까

**확률적 모델링**은 통계학 이론을 분석에 응용한 것이다. 초창기 머신 러닝 형태 중 하나로 가장 유명한 알고리즘은 **나이브 베이즈 알고리즘** 이다.  

<br>
베이즈 이론이란 사건 B가 발생함으로써 사건 A의 확률이 어떻게 변화하는지 표현한 이론이다. 아래의 공식이 베이즈 이론을 수식화한것이다.  $$P(A \mid B) = \frac{P(B \mid A)P(A)}{P(B)}$$
  


이 나이브 베이즈 알고리즘과 밀접하게 연관된 모델이 **로지스틱 회귀** (회귀 알고리즘이 아닌 분류알고리즘이다)이다. 로지스틱 회귀 알고리즘은 이벤트가 발생할 확률을 결정하는데 사용되는 통계 모델이다.

성공적인 첫 신경망은 **LeNet** 으로 합성곱 신경망과 역전파를 연결해 손글씨 숫자 이미지를 분휴하는 문제에 적용했다. 
>경사하강법이란 손실함수의 미분값의 크기가 점차 줄어드는 방향으로 가중치를 업데이트하며 손실 함수의 최소값을 찾아가는 방법을 말한다.

--- 
신경망은 첫 성공에 관심을 얻었지만, 이어 머신 러닝의 새로운 접근 방식인 커널 방법이 인기를 얻자 신경망은 잊혔다. 커널방법은 **결정 경계를 선형으로 만들기 어려운 상황에서 원본 데이터를 고차원으로 매핑해 선형 분류를 하는 것이다.** 
커널 방법을 이용한 기술 중 서포트 벡터 머신(Support Vector Machine, SVM)이 가장 유명하다. 

![1](/assets/img/study/deep/ch01/ch1-10.png)
<br>
데이터를 고차원 표현으로 매핑한 뒤 데이터 포인트 사이의 거리가 최대가 되는 최선의 결정 경계를 찾는다. 이 단계를 마진 최대화라고 지칭한다.
>커널 방법을 활용해 커널기법을 만들었다. 커널 방법을 통해, 컴퓨터에서 커널 방법을 용이하게 사용할 수 있게 되었다.

----

**결정 트리**는 플로차트 같은 구조를 가지며 입력 데이터 포인트를 분류하거나 주어진 입력에 대해 출력 값을 예측한다.

![1](/assets/img/study/deep/ch01/ch1-11.png)

특히, **랜덤 포레스트** 알고리즘은 결정트리 학습에서 기초한 것이다. 랜덤 포레스트 알고리즘이란 **훈련을 통해 구성해놓은 다수의 트리(나무)들로 부터 분류 결과를 취합해 결론을 얻는 것**이다.

랜덤 포레스트의 약점을 보완한 **그레디언트 부스팅 머신** 은 약한 예측 모델인 결정 트리를 앙상블(취합)하는 것을 기반으로 하는 머신 러닝 방법이다. 


> 이후 시간이 지나면서 신경망의 문제점이 점차 해결되며 신경망은 다시 관심을 얻기 시작했다.

---

딥러닝이 데이터로부터 학습하는 방법엔 두가지 특징이 있다. **층을 거치면서 점진적으로 더 복잡한 표현이 만들어진다**는 것과 **점진적인 중간 표현이 공동으로 학습된다**하는 것이다. 

최근 머신 러닝은 ChatGPT모델 등이 발표되며 많은 관심을 받고 있다.

----

## 1.3 왜 딥러닝일까? 왜 지금일까?

머신 러닝은 꽤나 역사를 가진 학문임에도 비교적 최근에서야 관심을 받는 분야가 됐다. 머신 러닝 발전에 제동이 걸린 이유는 세가지가 있다.
* 하드웨어
* 데이터셋과 벤치마크
* 알고리즘

첫 번째로 하드웨어는 시간이 지나며 비약적으로 발전했다. 머신 러닝에선 고성능의 하드웨어 자원이 필요한데, 이런 하드웨어 자워이 발전하지 못한 시기에 머신 러닝의 발전은 멈췄었다.

두 번째로 데이터 셋의 부족이다. 머신러닝은 방대한 양의 데이터 셋을 이용해야한다. 하지만 이런 데이터 셋을 갖추는 것은 저장장치가 부족한 시기와 데이터를 수집할 매체가 부족하다는 근거가 합쳐져서 머신러닝의 발전을 막았다.

마지막으로 알고리즘이다. 두 번의 AI겨울이 있다. 모두 알고리즘에 문제가 발생해서 머신 러닝에 대한 투자가 멈추는 계기가 됐다.

---
머신 러닝은 거대한 잠재성을 가진 학문이다. 따라서, 미래를 위해 다양한 국가들이 거대한 규모로 머신 러닝에 투자하는 추세다.




