---
title: Deep Learning Study Chapter.6
layout: post
categories : [ai]
image : /assets/img/study/deep/ch02/learning_flow.PNG
description: 케라스 창시자에게 배우는 딥러닝 개정 2판 Chapter.6 
customexcerpt: 딥러닝 모델을 개발하고 유지 관리 및 배포하는 단계를 학습한다.
---



<span class = "alert g">작성자 : 김대로</span>


# **6장. 일반적인 머신러닝 워크플로**

<!-- 아래 2줄은 목차를 나타내기 위한 심볼이니 건들지 말아 주세요 -->
* random line to make it work. This will be removed.
{:toc}

## **6.0 머신러닝 워크플로**    
해당 장에서는 머신러닝 문제에 접근하고 해결하는 데 사용하는 일반적인 단계별 청사진을 학습한다.

머신러닝 워크플로는 크게 세 단계로 구성된다.

1. **작업 정의** : 문제 영역과 클라이언트의 요청 사이의 관계를 이해한다. 데이터를 수집하고, 데이터의 정보를 이해하여, 적절한 모델을 선택한다.

2. **모델 개발** : 수집한 데이터를 전처리를 통해 머신러닝 모델로 처리할 수 있는 데이터로 가공한다. 모델의 평가 방법과 간단한 평가 기준을 선택한다. 그다음 초기 모델을 훈련시켜 **overfitting**한다. 이후 일반화 성능을 높이기 위하여 모델에 규제를 추가하고 튜닝한다.

3. **모델 배포** : 작업 결과를 고객에게 제공한다. 모델을 웹 서버, 모바일 앱, 웹 페이지 또는 임베디드 장치에 배포하고 실전에서의 모델의 성능을 모니터링한다. 이후 더 향상된 모델을 위해 배포하는 서비스를 통해 데이터를 수집한다.            



## **6.1 작업 정의** 

### **6.1.1 문제 정의**
머신 러닝 문제를 정의하려면 클라이언트가 무엇을 요구하는지, 어떤 목적으로 머신러닝을 사용하는지를 명확히 하는 것이 중요하다.

다음과 같은 몇가지 질문들을 통해 문제를 명확하게 정의할 수 있다.  

* 입력 데이터는 무엇인지? 어떤 것을 결과로 예측하려고 하는지? 가지고 있는 데이터로 모델을 훈련할 수 있는지?

* 어떤 종류의 문제인지?
  *  이진 분류 - 스팸 감지
  *  다중 분류 - 손글씨(MNIST) 분류
  *  다중 레이블 다중 분류 - 사진 검색 엔진     
    [multi_label](/assets/img/study/deep/ch06/2.PNG)
  *  스칼라 회귀 - 하나의 변수을 입력으로 하나의 예측값 출력
  *  벡터 회귀 - 여러개의 변수을 입력으로 여러개의 예측값 출력
  *  이미지 분할 - 이미지의 모든 픽셀에 클래스를 부여하는 것    
    [image segmentation](/assets/img/study/deep/ch06/3.PNG)
  *  랭킹 - 검색 엔진의 문서 노출 우선순위 결정 
  *  클러스터링 - label없이 데이터의 패턴을 파악하여 묶는 것
  *  강화 학습 - 행동에 대한 보상을 학습하여, 최대한의 보상을 얻는 행동이나 순서를 택하는 방법
  *  확률 또는 통계 분석 모델 등

* 기존의 솔루션은 어떠한 어떠한 것들이 있는지? 그리고 어떠한 방식으로 동작하는지?

* 배포하는 시스템에 어떠한 제약이 있는지? ex) 하드웨어의 한계, 소요 시간 등

### **6.1.2 데이터 수집** 
대부분의 머신 러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며, 비용이 많이 드는 단계이다.

* 사진 검색 엔진 프로젝트에서 1만개의 카테고리가 있을 때, 데이터를 얻기 위해서는 수십만 장의 이미지를 수동으로 카테고리 정보를 태깅해야 한다.

* 불량 쿠키 감지 모델의 경우 컨베이어 벨트 위에 카메라를 설치하여 수만 장의 이미지를 수집하고, 수동으로 정상인지 불량인지 레이블링 해야한다.

* 반면에, 음악 추천 엔진의 경우에는 사용자가 "좋아요"를 표시한 기록을 데이터로 사용할 수 있기 때문에, 새로운 데이터를 수집할 필요가 없다.

#### **대표성이 없는 데이터 주의하기**
훈련에 사용되는 데이터는 제품 환경에 있는 데이터를 대표하는 것이 중요하다.

음식 사진으로 요리 이름을 찾아주는 앱을 개발한다고 가정하자. 훈련 데이터로 전문가가 촬영한 밝고 먹음직스러운 음식사진을 학습시키면, 검증 정확도가 매우 높게 나왔음에도 불구하고 실제 사용자가 대충 찍은 저품질의 음식사진을 제대로 맞추지 못하는 경우가 발생한다.

이러한 문제는 훈련에 사용하는 데이터가 제품 환경에 있는 데이터를 대표하지 못하였기에 발생한 문제이며, **샘플링 편향(sampling bias)** 라고 한다.

따라서, 가능하다면 모델이 사용될 환경에서 직접 데이터를 수집하는 것이 바람직하다.

#### **데이터 이해**
모델 훈련을 시작하기 전에 데이터의 특성에 대한 올바른 통찰을 하는 것이 중요하다. Feature Engineering과 밀접하게 관련되어 있다.

* 데이터가 이미지나 자연어 텍스트를 포함한다면 몇 개의 샘플과 label를 직접 확인해야 한다.
* 데이터가 수치적인 특성을 가진다면, 히스토그램을 통해 값의 범위나 빈도를 파악해야 한다.
* 데이터가 위치 정보를 포함한다면 지도에 그려, 특정 패턴을 관측해야 한다.
* 결측 값을 가진다면, 여러 보간방법을 활용해 처리해야 한다.
* **타깃누출(target leaking)**을 확인해야한다. 타깃 누출이란 target 정보가 모델의 입력 데이터에 누출되고 있는 것을 의미한다. 데이터에 있는 모든 특성이 제품 환경에서도 동일한 형태로 제공될 수 있도록 타깃누출을 막아야 한다.

### **6.1.4 성공 지표 선택**
프로젝트의 목표에 부합하는 성공 지표를 선택해야 한다.

클래스 분포가 균일한(클래스 데이터 수가 균일) 분류 문제에서는 정확도와 ROC(Receiver Operating Characteristic) 곡선 아래 면적인 ROC AUC가 일반적인 지표이다.

클래스 분포가 균일하지 않은 문제나 랭킹 문제, 다중 레이블 문제에는 정밀도와 재현율을 사용한다. 다중 레이블 문제 또한, 정확도와 ROC AUC의 가중 평균을 사용할 수 있다.

[Confusion Matrix](/assets/img/study/deep/ch06/4.PNG)

* **정밀도(Precision)** : 양성으로 예측된 것 중에 실제 양성인 것 
* **재현율(Recall)** : 실제 양성 중에서 양성으로 예측된 것
* **정확도(Accuracy)** : 얼마나 정확하게 예측하였는가   
  
[ROC Curve](/assets/img/study/deep/ch06/5.PNG)

분류 문제에서는 주어진 문제의 성공 지표를 직접 최적화(손실함수로 바꾸는 것)하는 것이 불가능한 경우가 많다.

이러한, 분류 작업에서는 ROC AUC를 대신하기 위해 cross-entropy 지표를 활용화여 최적화하는 것이 일반적이다.

[Loss function](/assets/img/study/deep/ch06/6.PNG)

## **6.2 모델 개발**

### **6.2.1 데이터 준비**

딥러닝 모델은 일반적으로 원시 데이터를 사용하지 않는다. 데이터 전처리의 목적은 주어진 원본데이터를 신경망에 적용하기 쉽도록 만드는 것이다. 이러한 전처리에는 주로 벡터화, 정규화, 결측값 처리 등이 있다. 많은 전처리 기법들이 도메인(이미지, 텍스트)에 특화 되어 있기 때문에 전부 다루지는 못하고, 모든 데이터 분야에 공통되는 사항에 대해 알아본다.

#### **벡터화**
신경망에서 모든 입력과 타깃은 부동 소수점 데이터로 이루어진 텐서의 형태를 가져야 한다. 따라서, 사운드, 이미지, 텍스트 등을 텐서로 바꾸어야 하는데 이를 **데이터 벡터화(data vectorization)** 라고 한다.

4장에서 리뷰의 감정 분류 예제에서 텍스트를 정수 리스트로 변환하였고, 이를 one-hot 인코딩하여 float타입의 데이터로 이루어진 텐서로 바꾸어 학습을 진행하였다.

#### **값 정규화**
2장의 MNIST의 숫자 이미지 분류 실습에서, 이미지 데이터를 Grey scale 인코딩인 0~255 값으로 인코딩 했었다. 즉, 이미지의 각 픽셀 값은 0~255 사이의 값을 가졌었는데 우리는 이러한 값을 바로 사용하지 않고 255로 나누어 0에서 1 사이의 값을 가지도록 하였다. 이러한 방식을 **정규화** 라고 한다.

데이터에서 어떠한 특성은 100~200 사이의 큰 값을 가지고, 어떠한 특성은 1~3 사이의 작은 값을 가지는 것처럼, 특성 값의 크기가 차이나는 경우 신경망 학습이 제대로 이루어지지 않을 수 있다.

업데이트 해야할 Gradient가 커져서 네트워크에 수렴하는 것을 방해하기 때문이다. 쉽게 말하면, 큰 값을 가지는 특성이 과도하게 학습되어, 작은 값을 가지는 특성들은 제대로 학습되지 못한다.

**따라서, 데이터의 모든 특성들은 0~1의 작고 균일한 값을 가지도록 정규화를 거쳐야 한다.**

#### **누락된 값 처리**
결측값을 처리하는 방법은 데이터 타입에 따라 달라진다.

* 특성 값이 범주형인 경우에는 '누락된 값'이라는 별도의 범주를 만드는 것이 바람직 하다.

* 특성 값이 수치형인 경우에는 '0'같은 임의의 값을 넣기 보다는 해당 특성의 평균이나, 선형 보간, 모델을 통한 예측을 통해 값을 대체하는 것이 좋다.

### **6.2.2 평가 방법 선택**
모델 개발 과정 전반에 걸친 모든 모델링 결정은 검증 지표에 의해 결정된다.

이전의 여러 장에서 다루었는데, 검증 지표는 주로 다음과 같은 세가지 방법을 사용한다.
* 홀드아웃 검증 : 데이터가 풍부할 때 사용
* K-겹 교차 검증 : 홀드아웃 검증을 사용하기에 샘플 개수가 너무 적을 때 사용
* 반복 K-겹 교차 검증 : 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용

### **6.2.3 기준 모델 뛰어넘기**
모델을 다루기 시작할 때 초기 목표는 **검정력(statistical power)** 을 달성하는 것이다. 즉, 아주 간단한 기준점을 넘을 수 있는 작은 모델을 만드는 것이다.

* 검정력 : 대립가설이 사실일 때, 이를 사실로서 결정할 확률을 말한다. 즉, 검정력을 가진다는 말은 모집단에서 실제로 존재하는 차이나 효과를 검출할 수 있는 능력을 가졌다는 것을 의미한다. 
  

<br/>
이 단계에서 가장 중요하게 중점을 두어야 하는 것은 다음과 같다.    

* 특성 공학 : 유용하지 않은 특성을 제외하거나, 도메인 지식을 활용하여 유용한 새 특성을 만든다.
* 구조에 대한 올바른 가정 : Dense NN, CNN, RNN, Transformer 등 어떤 종류의 모델 구조를 사용할 지, 작업에 맞는 접근 방법을 택해야 한다.
* 좋은 훈련 옵션 선택 : 어떤 Loss Function을 사용할 것인가, 배치 크기와 learning_rate는 얼마로 할 것인가 결정해야 한다.

### **6.2.4 모델 용량 키우기: 과대적합 모델 만들기**
검정력을 가진 모델을 얻었다면, 모델이 충분한 성능을 내는지 확인 해야한다. 가장 이상적인 모델은 underfitting과 overfitting 사이 경계에 있는 모델이 이상적이다.

모델의 용량을 얼마나 크게 해야될지 알기 위해서는 과대적합된 모델을 만들어야 한다. 
1. layer를 추가한다.
2. layer의 크기를 키운다. -> layer의 노드 수 증가
3. 더 많은 epoch를 훈련한다.
   
검증 데이터에서 모델 성능이 감소하기 시작했을 때가 overfitting에 도달한 것이다.

### **6.2.5 모델 규제와 하이퍼 파라미터 튜닝**
모델이 overfitting 되었다면, 다음 목표는 일반화 성능을 최대화하는 것이다.

반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가해야한다. 이러한 과정에서 다음과 같은 시도를 해야한다.
* 모델의 구조 변경 - 층을 추가하거나 제거
* 드롭아웃 - 불필요한 노드 날리기
* 모델이 작다면 L1이나 L2 규제 추가하기
* 최적의 설정을 찾기 위해 하이퍼파라미터(층의 크기, 학습률 등)를 바꾸어 시도하기
* 더 많은 데이터를 수집하고, annotation을 만들고, 더 나은 특성을 찾고, 불필요한 특성을 제거

만족할 만한 모델 설정을 얻었다면, 가용한 모든 데이터를 사용해서 제품에 투입할 최종 모델을 훈련시킨다. 그리고 마지막에 딱 한번만 테스트 데이터셋을 사용해 평가한다. 

테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정의 신뢰성이 없거나 하이퍼파라미터를 튜닝하는 동안 검증데이터에 overfitting된 것이다. 이런 경우에는 반복 K-겹 교차 검증 같은 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋다.


## **6.3 모델 배포**

### **6.3.1 고객에게 작업을 설명하고 기대치 설정하기**
AI 시스템에 비전문적인 사람들의 기대를 오롯히 충족하는 것은 불가능에 가깝다. 

"모델은 98% 정확도를 달성했다."와 같은 추상적인 문장 대신 "평균적으로 14개의 부정 거래를 놓치며 266개의 부정 거래를 정확하게 감지합니다."라고 말해야한다.

다시 말해, **모델의 성능 지표와 비지니스 목표를 명확하게 연관 지어야 한다.**

출시할 때, 적용할 핵심적인 파라미터에 관해서도 고객과 논의해야 한다.

ex) 부정 거래로 표시할 확률 임계값을 정하는 일. 임계 값이 달라지면 거짓 음성 비율과 거짓 양성 비율이 달라지기 때문에, 이러한 결정에는 **절충점** 이 필요하며 비지니스에 대한 깊은 이해가 있어야 한다.

### **6.3.2 추론 모델 배치하기**
훈련된 모델을 파이썬 모델 객체와 똑같은 객체를 제품에 넣는 경우는 드물다.

파이썬이 아니라 다른 방식으로 모델을 저장할 수 있다.  
* 제품 환경이 파이썬을 지원하지 않을 수 있다. ex) 모바일 앱, 임베디드 시스템
* 애플리케이션이 파이썬으로 작성되지 않은 경우 ex) Java Script, C++

제품 모델은 훈련이 아니라 예측을 만들기 위해서만 사용된다 (추론)

따라서, 모델의 속도를 높이고 메모리 사용량을 줄일 수 있는 다양한 최적화를 수행할 여지가 존재한다.

### **REST API로 모델 배포하기**
모델을 제품으로 바꾸는 가장 보편적인 방식이 REST API이다. 서버나 클라우드 인스턴스에 tensorflow를 설치하고 REST API로 모델의 예측을 요청한다. Flask(또는 다른 파이썬 웹 개발 라이브러리)를 사용해서 직접 serving 앱을 만들 수 있다. 또는 API 방식의 모델 배포를 위한 tensorflow 자체 라이브러리인 tensorflow serving을 사용하여 몇 분만에 케라스 모델을 배포할 수 있다.

다음과 같은 경우 API 배포 방식을 사용해야 한다.  
* 모델의 예측을 사용할 어플리케이션이 안정적으로 인터넷에 접속할 수 있어야 한다.
* 애플리케이션의 응답 속도에 대한 요구 사항이 엄격하지 않을 때. 요청, 추론, 응답의 과정에 500ms정도가 소요됨.
* 전달되는 입력데이터가 암호화되지 않은 형태의 데이터이어야 한다.

ex) 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용 카드 부정 거래 감지 프로젝트, 위성 이미지 프로젝트 ...

REST API로 모델을 **직접 서비스를 구성할지 또는 관리형 클라우드 서비스를 사용할지 결정** 해야한다.

ex) Google의 Cloud AI Platform은 텐서플로 모델을 Google Cloud Storage로 업로드하기만 하면 추론 요청을 보낼 수 있는 API 엔드포인트를 제공한다. 배치 예측, 로드 밸런싱, 확장 같이 실전에 필요한 많은 사항들을 처리해 준다.

### **장치로 모델 배포하기**
가끔 모델을 애플리케이션이 실행되는 동일한 장치(스마트폰, 임베디드 등의 작은 장치)에서 구동해야 하는 경우가 있다.

다음과 같은 경우 장치에 모델을 배포한다.  
* 모델의 응답 속도에 대해 엄격하거나 인터넷 연결이 불안정한 환경
* 대상 장치의 메모리와 전력 조건에서 실행될 수 있도록 모델을 작게 만들 수 있는 경우. tensorflow 모델 최적화 도구(Model Optimization Toolkit)를 활용
* 가장 높은 정확도를 달성하는 것이 중요하지 않은 경우. 최상의 모델보다 낮은 성능의 모델을 배포
* 입력 데이터가 매우 민감한 정보라서 원격 서버에서 암호화가 해제되면 안되는 경우

스팸 감지 모델은 채팅 앱의 일부로 사용자 스마트폰에서 실행되어야 한다. 메세지는 엔드-투-엔드로 암호화되고 따라서 원격에 호스팅된 모델이 읽을 수 없기 때문이다. 

비슷하게, 불량 쿠키 감지 모델 같은 경우는 응답 속도 제약이 엄격하므로 공장 안에서 실행되어야 한다.

<br/>

케라스 모델을 스마트폰이나 임베디드 장치에 배포하기 위한 방법은 **텐서플로 라이트(Tensorflow Lite)** 이다.  
* 효율적인 온-디바이스 딥러닝 추론을 위한 프레임워크로 안드로이드, iOS 스마트폰은 물론 ARM64 기반의 컴퓨터, 라즈베리 파이 또는 특정 마이크로컨트롤러에서 실행가능하다.
* 케라스 모델을 텐서플로 라이트 포맷으로 쉽게 변환하기 위한 변환기를 포함한다.

### **브라우저에 모델 배포하기**
일반적으로 애플리케이션이 REST API로 원격 모델에 요청을 보낼 수 있지만 사용자 컴퓨터의 브라우저에서 바로 모델을 실행하면 서버의 비용을 크게 줄일 수 있다는 장점이 있습니다.

다음과 같은 경우 브라우저 배포 방식을 사용한다.   
* 사용자 측에서 계산을 수행하면 서버 비용을 크게 줄일 수 있는 경우
* 입력 데이터가 사용자의 컴퓨터 또는 핸드폰에 있는 경우
* 애플리케이션의 응답 속도 제약이 엄격한 경우
* 모델을 내려받아 저장한 후 인터넷이 연결되지 않은 상태에서 작동하는 앱이 필요한 경우

모델이 충분히 작아 사용자 장치의 CPU, GPU, RAM을 독차지하지 않을 때 이 방식을 사용한다. 또한 전체 모델을 사용자 장치에 내려받기 때문에 모델에 관해 비밀로 유지할 것이 없어야 한다.

저장된 케라스 모델을 **TensorFlow.js(자바스크립트 딥러닝 라이브러리)** 로 임포트하여 브라우저 기반 앱이나 데스크톱의 일렉트론 앱의 일부로 사용가능


### **추론 모델 최적화**
추론을 위한 모델 최적화는 가용 전력과 메모리에 엄격한 제한이 있는 환경(스마트폰, 임베디드 장치)이나 응답 속도에 대한 높은 제약이 있는 애플리케이션에 모델을 배포할 때 매우 중요하다.

모델을 TensorFlow.js나 TensorFlow Lite로 내보내기 전에 항상 최적화가 이루어져야 한다.

최적화 기법은 다음과 같다.    
* 가중치 가지치기 : 가중치 텐서의 모든 값이 예측에 동일한 기여를 하지 않는다. 즉, 중요한 특성이 있고 중요하지 않은 특성이 있다는 뜻. 따라서, 가중치가 큰 값만 남기면 모델 층에 있는 파라미터 개수를 크게 낮출 수 있으며, 이는 메모리와 계산 자원의 축소로 이어진다.
* 가중치 양자화 : 딥러닝 모델은 단정도 부동 소수점 가중치로 훈련된다. 하지만 가중치를 8비트 정수(int8)로 압축하는 것이 가능하다. 크기는 1/4이지만 원본 모델의 정확도에 거의 가까운 추론용 모델을 얻을 수 있다.

텐서플로에는 케라스 API와 긴밀하게 통합된 최적화 도구(tensorflow model_optimization)가 존재한다.

### 6.3.4 모델 유지 관리
영원한 모델은 없다. 시간이 지남에 따라 제품 환경의 데이터 속성이 변화고 점진적으로 모델의 성능과 타당성이 감소한다.

음악 추천 시스템의 수명은 몇 주밖에 되지 않고, 이미지 검색 엔진은 최상의 경우 몇 년 밖에 되지 않는다.

모델이 출시되자마자 이 모델을 대체할 다음 세대 모델의 훈련을 준비해야한다.

따라서, 제품 환경의 데이터 변화를 꾸준히 모니터링 해야하고, 데이터를 수집하면서 annotation을 해야한다.
