---
title: Intro to SQL 
layout: post   
categories : Database, SQL, kaggle
image : /assets/img/수료증/윤수빈-수료증.png
description: Learn SQL for working with databases, using Google BigQuery 
customexcerpt: "Intro to SQL"   
---

## 00. Intro BigQuery and SQL
---
> **BigQuery**
> - 구글에서 관리형 클라우드 제품으로 제공하는 분석 엔진이다.
> - 웹 인터페이스, CLI 또는 SDK를 사용해 액세스할 수 있다.
> - ANSI SQL과 완벽하게 호환돼 다른 SQL 시스템을 이용하듯 사용할 수 있다.
> - 열 데이터 저장소이다.
>   - 열 데이터 저장소이기에 한 번에 한 행씩 수행하는 INSERT 및 UPDATE문을 빠르게 실행하도록 만들어지지 않았다.
>   - 대신, 로드 또는 스트리밍 방법을 사용해 훨씬 더 빠르게 데이터를 삽입할 수 있다.

>**용어 정리**
>> **테이블**  
>> 관계형 데이터베이스의 기본은 열과 행으로 구성된 테이블이다.  
>> 하지만 BigQuery는 내부적으로 열 단위로 개별 값을 저장하는 <u>열 데이터 저장소</u>이다.
>
>> **테이블 스키마**  
>> 테이블의 구조를 스키마라고 한다.  
>> 원하는 데이터를 효과적으로 사용하기 위해 테이블 스키마를 잘 정의해야한다.
>
>> **별칭**  
>> 'AS' 키워드를 사용해 열 또는 기타 데이터베이스 객체의 이름을 다른 이름으로 바꾼다.  
>> 'COUNT (*) AS num' 대신 'COUNT (*) num'로 'AS'를 생략하는 경우가 더 많다.
>
>> **주석**  
>> 한줄 주석은 '--(이중 하이픈)'을 사용
>> 여러 줄 주석은 '/* (주석 내용) */'을 사용
>
>> **SELECT**  
>> SELECT는 FROM으로 지정한 테이블에서 검색하려는 열의 데이터를 정의한다.
>
>> **FROM**  
>> FROM은 데이터 소스로 사용할 항목을 지정한다.
>
>> **WHERE**  
>> WHERE은 필터링 할 행을 결정한다.  
>> WHERE은 선택사항이지만 아래와 같은 이유들로 써주는 것이 좋다.
>> - 더 적은 데이터를 반환한다.
>> - 새로운 유형의 데이터 수용 시 테이블이 커지는 경우 검색어를 무한정 확장하지 않는다.
>> - 대부분의 SQL을 더 빨리 실행할 수 있게 해준다.
>
>> **GROUP BY**  
>> GROUP BY는 데이터를 집계하는 데 사용한다.  
>> ```sql
>> -- cf. GROUP BY를 사용하여 데이터 집계
>> SELECT CODE.CodeMean KindName, count(*) ct 
>> FROM EQUIP, CODE
>> WHERE EQUIP, KindCodeSeq = CODE.CodeSeq  
>> and EQUIP.FacilitySeq = ?
>> GROUP BY CODE.CodeMean
>>```
>
>>**ORDER BY**  
>> SQL쿼리 결과는 비결정적이기 때문에 결과를 반환하는 순서를 보장하지 않는다.  
>> 하지만 ORDER BY를 사용해 일관된 결과를 얻을 수 있다.
>
>> **LIMIT**  
>> LIMIT는 단순히 반환하려는 행 수의 상한을 지정한다.  
>> 보통 쿼리로 반환하는 데이터의 양은 LIMIT로 제한해야 한다.

## 01. Getting Started With SQL and BigQuery
---

1. BigQuery 명령
    ```python
    # BigQuery를 사용하기 위해 Python 패키지 가져옴
    from google.cloud import bigquery

    # Client 객체 생성
    client = bigquery.Client()


    # dataset는 테이블의 모음
    # 'hacker_news' 과 관련된 dataset을 구성
    dataset_ref = client.dataset("hacker_news", project="bigquery-public-data")

    # API 요청 - dataset 가져오기
    dataset = client.get_dataset(dataset_ref)


    # list_tables()을 사용하여 dataset의 테이블을 나열
    # 'hacker_news' dataset의 모든 테이블 나열
    tables = list(client.list_tables(dataset))

    # dataset에 있는 모든 테이블 출력
    for table in tables:
        print(table.table_id)


    # dataset를 가져온 방법과 유사하게 테이블을 가져오기
    table_ref = dataset_ref.table("full")

    # API 요청 - 테이블 가져오기
    table = client.get_table(table_ref)
    ```
2. 테이블 스키마
   ```python
   # 'hacker_news' dataset의 'full' 테이블에 있는 모든 열에 대한 정보 출력
   table.schema


   # list_rows()를 사용하여 처음 다섯 줄만 반환
   # to_dataframe()는 pandas DataFrame으로 빠르게 변환할 수 있는 BigQueryRowIterator 개체를 반환
   client.list_rows(table, max_results=5).to_dataframe()

   # list_rows()를 사용하여 특정 열의 정보만 반환
   client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()
   ```
## 02. Select, From & Where
---
<details>
    <summary>Bigquery 설정</summary>

    from google.cloud import bigquery

    client = bigquery.Client()
    dataset_ref = client.dataset("openaq", project="bigquery-public-data")
    dataset = client.get_dataset(dataset_ref)
    tables = list(client.list_tables(dataset))

    for table in tables:
        print(table.table_id)

</details><br>

01. Query 생성
    ```python
    query = """
            SELECT city
            FROM `bigquery-public-data.openaq.global_air_quality`
            WHERE country = 'US'
            """
    ```
02. dataset에 query 보내기
    ```python
    client = bigquery.Client()

    # query()를 사용하여 쿼리 설정
    query_job = client.query(query) 

    # API 요청 - query를 실행하고, pandas DataFrame으로 반환
    us_cities = query_job.to_dataframe()

    # 다른 DataFrame과 마찬가지로 사용할 수 있는 us_cities라는 pandas DataFrame 사용 예시
    us_cities.city.value_counts().head()
    ```
03. 대규모 DataSet 작업
    ```python
    query = """
            SELECT score, title
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = "job"
            """
    
    # QueryJobConfig 객체를 생성하여, 쿼리를 실행하지 않고 크기 추정
    dry_run_config = bigquery.QueryJobConfig(dry_run=True)

    # API 요청 - 비용 추정을 위한 실행 쿼리
    dry_run_query_job = client.query(query, job_config=dry_run_config)

    print(f'This query will process {dry_run_query_job.total_bytes_processed} bytes')
    ```

    ```python
    # 1MB를 초과하기 때문에 에러나는 코드
    
    ONE_MB = 1000*1000
    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)

    safe_query_job = client.query(query, job_config=safe_config)

    safe_query_job.to_dataframe()
    ```

    ```python
    # 에러가 발생하지 않도록 범위를 늘린 코드

    # query가 1GB 미만인 경우에만 실행
    ONE_GB = 1000*1000*1000
    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)

    # query 설정 (1GB 미만인 경우에만 실행)
    safe_query_job = client.query(query, job_config=safe_config)

    # API 요청 - query를 실행하고, pandas DataFrame을 반환
    job_post_scores = safe_query_job.to_dataframe()

    # job posts의 평균 점수 출력
    job_post_scores.score.mean()
    ```


## 03. Group By, Having & Count
---

<details>
    <summary>Bigquery 설정</summary>

    from google.cloud import bigquery

    client = bigquery.Client()

    dataset_ref = client.dataset("hacker_news", project="bigquery-public-data")

    dataset = client.get_dataset(dataset_ref)

    table_ref = dataset_ref.table("comments")

    table = client.get_table(table_ref)

    client.list_rows(table, max_results=5).to_dataframe()

</details><br>

01. Query 생성 & 결과값 pandas DataFrame에 저장
    ```python
    query_improved = """
                        SELECT parent, COUNT(1) AS NumPosts
                        FROM `bigquery-public-data.hacker_news.comments`
                        GROUP BY parent
                        HAVING COUNT(1) > 10
                        """

    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)
    query_job = client.query(query_improved, job_config=safe_config)

    improved_df = query_job.to_dataframe()

    improved_df.head()
    ```

02. Good Query & Bad Query
    ```python
    good_query = """
                    SELECT parent, COUNT(id)
                    FROM `bigquery-public-data.hacker_news.comments`
                    GROUP BY parent
                """

    # author col이 GROUP BY 되지 않았기에 오류
    bad_query = """
                    SELECT author, parent, COUNT(id)
                    FROM `bigquery-public-data.hacker_news.comments`
                    GROUP BY parent
                """
    ```
## 04. Order By
---
<details>
    <summary>Bigquery 설정</summary>

    from google.cloud import bigquery

    client = bigquery.Client()

    dataset_ref = client.dataset("nhtsa_traffic_fatalities", project="bigquery-public-data")

    dataset = client.get_dataset(dataset_ref)

    table_ref = dataset_ref.table("accident_2015")

    table = client.get_table(table_ref)

    client.list_rows(table, max_results=5).to_dataframe()

</details><br>

01. Query 생성 & 결과값 pandas DataFrame에 저장
    ```python
    # ORDER BY 를 사용함으로 사고가 많이 발생한 날짜가 먼저 반환
    query = """
            SELECT COUNT(consecutive_number) AS num_accidents, 
                EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week
            FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`
            GROUP BY day_of_week
            ORDER BY num_accidents DESC
            """

    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**9)
    query_job = client.query(query, job_config=safe_config)

    accidents_by_day = query_job.to_dataframe()

    accidents_by_day
    ```

## 05. As & With
---
```python
# 날짜별로 정렬된 날짜당 트랜잭션 수를 select하기 위한 Query
query_with_CTE = """ 
                 WITH time AS 
                 (
                     SELECT DATE(block_timestamp) AS trans_date
                     FROM `bigquery-public-data.crypto_bitcoin.transactions`
                 )
                 SELECT COUNT(1) AS transactions,
                        trans_date
                 FROM time
                 GROUP BY trans_date
                 ORDER BY trans_date
                 """
```

## 06. Joining Data
---
```python
# 파일 수에 따라 정렬된 라이센스당 파일 수를 결정하는 Query
query = """
        SELECT L.license, COUNT(1) AS number_of_files
        FROM `bigquery-public-data.github_repos.sample_files` AS sf
        INNER JOIN `bigquery-public-data.github_repos.licenses` AS L 
            ON sf.repo_name = L.repo_name
        GROUP BY L.license
        ORDER BY number_of_files DESC
        """
```

![윤수빈 수료증](/assets/img/수료증/윤수빈-수료증.png)