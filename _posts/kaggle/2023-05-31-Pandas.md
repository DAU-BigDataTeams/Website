---
title: "데이터분석을 위한 Pandas Library에 대해 알아보자!(feat. Kaggle)"
layout: post   
categories : [kaggle]
image : /assets/img/수료증/송시무_pandas수료증.png 
description: Kaggle의 Pandas 과정 정리  
customexcerpt: "kaggle의 pandas 과정을 통해 pandas의 기본적인 기능에 대해 알아보자."
---
​
<span class = "alert g">작성자 : 송시무</span>
​
​
<!-- 아래 2줄은 목차를 나타내기 위한 심볼이니 건들지 말아 주세요 -->
* random line to make it work. This will be removed.
{:toc} 

# **1. Pandas**

 앞의 내용에 대해 복습하는 차원에서 kaggle의 pandas 과정을 수료한 내용에 관해 포스팅하고자 한다. (참고로 kaggle 복습 전에 가겸님의 pandas post를 봤는데 너무 잘 정리해주셔서 해당 이론을 상기시키는데 도움이 되었다!) 

가겸님의 포스팅 내용을 참고하여 pandas library의 핵심적인 부분에 대해 아주 간단히 요약하면 다음과 같다.
- 사용 목적 : 데이터 조작과 분석
- 이를 위해 DataFrame, DataSeries 자료형과 각종 기능(함수)을 제공
- 유사한 목적의 SQL에 비해 빠르고 가볍다는 장점이 있음

pandas library를 이용한 데이터 분석 결과물은 금융, 마케팅, 의료, 교통, 소셜 미디어 등의 다양한 분야에서 데이터 기반 의사 결정의 정확성과 효율성을 높이기 위해 활용되고 있다.   

이제 본격적으로 kaggle의 pandas 과정을 통해 pandas의 주요 기능을 살펴보자. 

# **2. Kaggle Pandas 과정**

## **1. Creating, Reading and Writing**
### **Introduction**
: pandas에 대해 알아보고 데이터를 만드는 방법과 이미 존재하는 데이터를 가져오는 방법을 알아보자.

### **Creating data**
: pandas에서 제공하는 데이터 형태 2가지(Series, DataFrame)에 대해 알아보고, 데이터를 생성해보자.
간략히 설명하면 DataFrame은 table(표)이고, Series는 표를 구성하는 하나의 열(column)이다.

1) DataFrame
- 행과 열로 이루어진 2차원 table(표)이다.
- 각 column(열)은 Series로 구성된다.  
- 각 entry(요소)는 숫자형, 문자열, 불린형(boolean) 등 다양한 자료형을 포함할 수 있다.


 생성방법
~~~py
pd.DataFrame([[1,2,3],[4,5,6]])
~~~


결과
<table>
<thead>
  <tr>
    <th></th>
    <th>0</th>
    <th>1</th>
    <th>2</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>0</td>
    <td>1</td>
    <td>2</td>
    <td>3</td>
  </tr>
  <tr>
    <td>1</td>
    <td>4</td>
    <td>5</td>
    <td>6</td>
  </tr>
</tbody>
</table>

코드
~~~py
pd.DataFrame({'Yes': [50, 21], 'No': [131, 2]})
~~~

결과

<table>
<thead>
  <tr>
    <th></th>
    <th>Yes</th>
    <th>No</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>0</td>
    <td>50</td>
    <td>131</td>
  </tr>
  <tr>
    <td>1</td>
    <td>21</td>
    <td>2</td>
  </tr>
</tbody>
</table>

코드
~~~py
pd.DataFrame({'A': ['happy', 'sad'], 
              'B': ['hopeful', 'love']},
             index=['Day1', 'Day2'])
~~~


결과

<table>
<thead>
  <tr>
    <th></th>
    <th>A</th>
    <th>B</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Day1</td>
    <td>happy</td>
    <td>hopeful</td>
  </tr>
  <tr>
    <td>Day2</td>
    <td>sad</td>
    <td>love</td>
  </tr>
</tbody>
</table>



2) Series
- 일련의 데이터 값들이다.
- DataFrame을 구성하는 하나의 열이다.
- DataFrame이 table(2차원)이면 Series는 list(1차원)이다.
- 각 행 별로 labeling이 가능하다.
- 리스트(list)와 딕셔너리(dictionary) 형식으로 생성한다.  



* 생성 방법  

코드
~~~py
# 생성 명령어의 구조는 아래와 같다. 
pd.Series(data, index=index, name=name)

# 생성 예시 3가지를 살펴보자.
pd.Series([1, 2, 3, 4, 5])
~~~
결과
<pre>
0	1
1	2
2	3
3	4
4	5
dtype: int64
</pre>
코드
~~~py
pd.Series({'a':1,'b':2, 'c':3, 'd':4, 'e':5})
~~~
결과
<pre>
a	1
b	2
c	3
d	4
e	5
dtype: int64
</pre>
코드
~~~py
pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')
~~~

결과
<pre>
2015 Sales    30
2016 Sales    35
2017 Sales    40
Name: Product A, dtype: int64
</pre>
참고
- 생성 시에 별도로 index를 입력해주지 않으면 index는 0부터 시작한다.
- Series의 이름도 따로 입력해주지 않으면 None값이 부여된다.  
  

### **Reading data files**
: 데이터를 직접 만드는 경우도 많겠지만, 실제로 데이터 분석을 할 때는 기존에 만들어져 있는 데이터를 이용하는 경우가 더욱 많을 것이다. 이 때 가장 흔히 볼 수 있는 데이터의 형태가 CSV 파일이다.

> CSV(Commas Seperated Values) 파일
: 콤마로 구분된 값들로 구성된 파일이다. 

CSV 형태의 데이터를 가져와서 확인해보자.
~~~py
# 데이터 가져오기
df = pd.read_csv('파일경로/파일명.csv')

df = pd.read_csv("파일경로/파일명.csv", index_col=0)

# 데이터 확인
df.shape # 데이터프레임의 크기(행과 열)를 튜플 형태로 출력
df.head(n) # 상위 n개의 결과 값 출력. 기본 값은 n=5.
~~~

pandas libarary를 이용하여 데이터를 만들고, 읽어오는 방법을 알아보았다. 문서 작업을 하는 엑셀 프로그램에 비유하면 워크시트를 만들고, 기존에 만들어 놓은 파일을 불러오는 것에 해당되겠다.

## **2. Indexing, Selecting & Assigning**

### **Introduction**
: 데이터에 접근하고 선택하는 건 데이터 분석에 있어 가장 기본적이고 필수적인 기능이다. 엑셀에 비유하면 셀을 선택하고, 셀에 값을 입력하는 것과 같다.

### **Native accessors**
: Pandas에서 제공하는 기본 접근 방법과 속성에 대해 알아보자. python에서 속성에 접근하는 방식과 유사하다.
만약 DataFrame의 특정 행의 값에 접근하고자 한다면 [ ]연산자를 이용한다.
~~~py
df.column명
df['column명']

# 해당 컬럼의 특정 행 값 접근
df['column명'][숫자]
~~~

### **Indexing in pandas**
: 인덱싱 기법을 사용하여 데이터를 선택하는 방법을 알아보자. 앞서 살펴본 객체의 속성에 접근하는 것과 유사한 방식 외에 pandas에는 python에 없는 접근 방식이 있다. 바로 label기반으로 접근하는 loc와 index 기반으로 접근하는 iloc 연산자를 이용하는 방식이다.

**Index-based selection**
~~~py
# 특정 행 접근
df.iloc[행 번호] 

# 특정 행, 특정 열에 접근
df.iloc[행 번호,열 번호]

# 여러 행에 접근
df.iloc[[0,1,2]]
df.iloc[0:n] #첫번째부터 n-1까지
df.iloc[-n:] #끝에서부터 n번째 앞까지

# ex) df의 0번째 열의 1,2,3행에 접근
df.iloc[1:2, 0]
df.iloc[[1,2,3], 0]
~~~
**label-based selection**
~~~py
# 특정 행 접근
df.loc['행 이름']

# 특정 행, 특정 열 접근
df.loc['행 이름', '열 이름']

# 여러 행, 여러 열 접근
df.loc[['행 이름1', '행 이름2','행 이름3'], ['열 이름1', '열 이름2']]

# iloc와 loc의 차이점
# iloc는 파이썬의 인덱스 체계를 따르는 반면 loc는 그렇지 않다. 
df.iloc[0:9] # 0,1,2,3,4,5,6,7,8
df.loc[0:9] # 0,1,2,3,4,5,6,7,8,9

df.iloc[0:1000] # 1000개
df.loc[0:1000] # 1001개
~~~

### **Manipulating the index**
: 우리가 설정하는 인덱스는 set_index() 메서드를 이용하여 수정이 가능하다.  
~~~py
df.set_index("column명")
~~~

### **Conditional selection**
: 이제 특정 조건에 해당하는 entry에 접근하는 방법을 알아보자.
~~~py
df.컬럼명 == '특정 단어' #True/False를 return
df.loc[df.컬럼명 == '특정 단어'] 
df.loc[(df.컬럼명 == '특정 단어1') & (df.컬럼명 == '특정 단어2'))] # 논리연산자(&, | 등)로 조건 추가 가능
df.loc[df.컬럼명.isin(['단어1', '단어2'])] # 값 목록에 있는 데이터 선택 가능
df.loc[df.컬럼명.notnull()] # null이 아닌 값들을 추출
~~~

### **Assigning data**
: 특정 entry에 접근하는 방법을 알아보았으니 이제 접근한 entry에 데이터를 입력해보자.
~~~py
df['새 컬럼명'] = '새로운 값'
~~~

## **3. Summary Functions and Maps**
### **Introduction**
: 앞서 1, 2장에서 데이터를 불러오는 방법, 특정 구역에 접근하여 값을 입력 및 수정하는 방법에 대해 알아보았다. 엑셀에 비유하면 워크시트 파일을 불러와서 셀을 선택하고 값을 입력해본 것이다. 

이제 기본적인 세팅을 마쳤으니, 분석을 위한 기본적인 기능들을 알아보자.(엑셀에서 제공하는 여러 기능들 알아보는 느낌)

### **Summary funcions**
: 데이터 집계 함수를 사용하여 데이터(DataFrame, Series)의 요약 통계량(평균, 합계, 표준편차)을 계산해보자. 
~~~py
df.describe() # 주요 통계량 요약하여 출력
df.mean() # 평균 계산
df.unique() # 유일한 값 출력(결측치 포함)
df.value_count() # 값 발생 횟수 총합
~~~
### **Maps**
: 데이터에 함수를 적용하여 데이터를 변환하는 방법에 대해 알아보자. map(), apply() 함수 등을 활용할 것이다.



~~~py
# 기본 명령어 형식
df.컬럼명.map(값을 변경하기 위한 식) # 해당 시리즈 변경
df.컬럼명.apply(값을 변경하기 위한 식)

df.apply(값을 변경하기 위한 식) # 전체 데이터프레임 변경
~~~
## **4. Grouping and Sorting**
### **Introduction**
: 1, 2, 3장에서는 전체 DataFrame과 Series에 대해 다뤄 보았다. 하지만 현실에서 데이터를 분석할 때 분명 전체 데이터 뿐만 아니라 일부분만 사용할 때도 있을 것이다. 이를 위해 이번 장에서는 데이터를 그룹화하고 그룹 단위로 분석하는 법을 알아보자.

### **Groupwise analysis**
~~~py
df.groupby('column명') #특정 열 기준으로 그룹화
df.groupby(['column명1', 'column명2']) # 2개 이상의 컬럼을 묶어서 그룹화

df.groupby(['column명1']).'columms명2'.agg([함수]) #column 1에 대해 column 2를 기준으로 함수를 동시에 실행
~~~

 **Multi-indexes**  
: groupby()를 사용하다보면 작업에 따라 다중 인덱스(multi-index)가 생성되기도 한다. Multi-index(다중 인덱스)는 Pandas에서 데이터프레임(DataFrame)이나 시리즈(Series)의 인덱스에 여러 개의 레벨을 가지는 인덱스를 지칭한다.

다중 인덱스를 사용하면 데이터를 계층적으로 구조화하여 다양한 방식으로 접근하고 조작할 수 있다. 이를 통해 복잡한 데이터를 보다 유연하게 다룰 수 있다.

~~~py
df.groupby(['column명1', 'column명2']) #다중인덱스

multi_index = df.groupby(['column명1', 'column명2'])
multi_index.reset_index() # 다중 인덱스를 일반 인덱스로 다시 변환
~~~

### **Sorting**
: 데이터를 원하는 순서대로 가져오려면 정렬을 해야 한다. 이 때 쓰는 게 sorting() 함수다.

~~~py
df.sort_values(by='기준이 될 column명', ascending = False)# default : ascending = True

df.sort_index() # index를 기준으로 정렬
~~~

## **5. Data Types and Missing Values**
### **Introduction**
: 이번 장에서는 앞에서 다뤘던 DataFrame이나 Series 단위보다 더 작은 대상인 Data에 대해 알아볼 것이다. 데이터의 자료형에 대해 살펴보고, 결측값이 있는지 확인하는 법과 만약 결측값이 존재한다면 이를 대체하는 방법도 살펴보자.

### **Dtypes**
: Pandas에서 지원하는 데이터 유형
- 숫자(정수, 실수)
- 문자열
- bool 값
- 시간 간격
- 날짜 등

* Dtype 확인하는 법
~~~py
df.dtype # 모든 dataFrame에 대한 dtype 리턴
df.column명.dtype # 컬럼 단위에도,
df.index.dtype # index 단위에도 적용 가능하다.  
~~~

### **Missing data**
: data가 주어지지 않은 entry는 NaN 값을 갖는다. 이 NaN 값(결측값)을 처리하는 방법이다. 결측값의 확인, 제거, 대체 등에 대해 알아보자.
~~~py
pd.isnull() # 결측값의 유무에 대해 True/False로 반환

df[pd.isnull(df.column명)] # 특정 열에서 결측값이 있는 행들로 이루어진 데이터프레임 반환

pd.isnull().sum() # 결측값 갯수 확인

pd.notnull() # 결측값이 아닌 값에 대해 True/False로 반환 

df.fillna("Unknown") # 결측값을 특정값("Unknown")으로 채운다 
~~~
## **6. Renaming and Combining**
### **Introduction**
: 앞에서 통계를 내고, table 안에 채워지는 데이터에 대해 알아보았다. 이제 본격적으로 데이터를 조작해보자. 데이터의 이름을 변경하고 데이터를 병합해보자. 

### **Renaming**
: 열 또는 인덱스의 이름을 일괄적으로 변경해보자.
~~~py
df.rename(columns={'기존 이름': '새로운 이름'})
df.rename(index={0: '새로운 이름1', 1: '새로운 이름2'})
df.rename_axis("새로운 행 이름", axis='rows').rename_axis("새로운 열 이름", axis='columns')
~~~


### **Combining**
: 다양한 데이터 프레임을 결합해보자. Pandas에는 데이터 결합을 위한 3가지 함수가 있다.
- concat()
- join()
- merge()  
  
* 예시

~~~py
pd.concat([df1, df2, df3], axis=0)
df1.join(df2, on='key', how='inner')
pd.merge(df1, df2, on='key', how='inner')
~~~

# **3. 마무리**

Kaggle의 pandas 과정을 정리하며 pandas를 복습해보았다. 기존에 소영님이 작성한 pandas 포스트에서 기능적인 부분에 대해 너무 잘 설명해주셔서 본 포스트는 조금은 더 거시적인 관점에서 작성해보았다. 

이상으로 포스팅을 마친다.

![d](/assets/img/수료증/송시무_pandas수료증.png)